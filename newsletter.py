import datetime as dt
from urllib.parse import urlparse, urlunparse
from zoneinfo import ZoneInfo
import re

from jinja2 import Environment, FileSystemLoader

from scrapers import (
    load_config,
    fetch_all_articles,
    filter_yesterday_articles,
    filter_out_finance_articles,
)
from categorizer import categorize_articles
from summarizer import summarize_overall, refine_article_summaries
from mailer import send_email_html


def _log(step: str, n: int):
    print(f"ğŸ§¾ {step}: {n}ê±´")


def _normalize_link(url: str) -> str:
    """
    ë§í¬ ì¤‘ë³µ ì œê±°ìš© ì •ê·œí™”:
    - query/fragment ì œê±°
    - host ì†Œë¬¸ì
    - trailing slash ì •ë¦¬
    """
    if not url:
        return ""
    try:
        p = urlparse(url)
        netloc = (p.netloc or "").lower()
        path = p.path or ""
        if path != "/" and path.endswith("/"):
            path = path.rstrip("/")
        return urlunparse((p.scheme, netloc, path, "", "", ""))
    except Exception:
        return url or ""


def _normalize_title(title: str) -> str:
    """
    (ë§í¬ê°€ ë¹„ì–´ìˆì„ ë•Œë§Œ) ìµœì†Œí•œì˜ ì œëª© ì •ê·œí™”:
    - ê³µë°± ì •ë¦¬
    - ë”°ì˜´í‘œ/ê´„í˜¸ ì •ë„ë§Œ ì œê±°
    """
    t = (title or "").strip().lower()
    t = re.sub(r"\s+", " ", t)
    t = re.sub(r"[â€œâ€\"'â€™`]", "", t)
    t = re.sub(r"[$begin:math:display$$end:math:display$$begin:math:text$$end:math:text$<>]", "", t)
    return t


def dedup_articles_only_duplicates(articles):
    """
    âœ… ëª©ì : 'ì¤‘ë³µë§Œ' ì‚­ì œí•˜ê³  ê¸°ì‚¬ ìˆ˜ëŠ” ìµœëŒ€ ìœ ì§€
    1) ë§í¬ ì •ê·œí™” ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±° (ì›ì¹™)
    2) ë§í¬ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì •ê·œí™”ê°€ ì‹¤íŒ¨í•œ ê²½ìš°ì—ë§Œ:
       (ì œëª© ì •ê·œí™” + ì–¸ë¡ ì‚¬ + ë°œí–‰ì¼(date))ì´ ì™„ì „íˆ ê°™ì„ ë•Œë§Œ ì œê±°
    """
    out = []
    seen_links = set()
    seen_fallback = set()

    for a in articles:
        link_raw = getattr(a, "link", "") or ""
        link_key = _normalize_link(link_raw)

        # 1) ë§í¬ê°€ ìˆìœ¼ë©´ ë§í¬ë¡œë§Œ ì¤‘ë³µ ì œê±°
        if link_key:
            if link_key in seen_links:
                continue
            seen_links.add(link_key)
            out.append(a)
            continue

        # 2) ë§í¬ê°€ ì—†ì„ ë•Œë§Œ ë§¤ìš° ì œí•œì ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
        title_key = _normalize_title(getattr(a, "title", "") or "")
        source_key = (getattr(a, "source", "") or "").strip().lower()

        try:
            pub_date = getattr(a, "published").date()
        except Exception:
            pub_date = None

        fb_key = (title_key, source_key, pub_date)
        if title_key and source_key and pub_date is not None:
            if fb_key in seen_fallback:
                continue
            seen_fallback.add(fb_key)

        out.append(a)

    return out


def render_newsletter_html(cfg, categorized, yesterday_summary: str) -> str:
    tz = ZoneInfo(cfg.get("timezone", "Asia/Seoul"))
    now = dt.datetime.now(tz=tz)
    today_str = now.strftime("%Y-%m-%d (%a)")

    env = Environment(loader=FileSystemLoader("."), autoescape=True)
    template = env.get_template("template_newsletter.html")

    return template.render(
        today_date=today_str,
        yesterday_summary=yesterday_summary,
        acuvue_articles=categorized.acuvue,
        company_articles=categorized.company,
        product_articles=categorized.product,
        trend_articles=categorized.trend,
        eye_health_articles=categorized.eye_health,
    )


def main():
    cfg = load_config("config.yaml")
    tz = ZoneInfo(cfg.get("timezone", "Asia/Seoul"))

    today = dt.datetime.now(tz=tz).date()
    yesterday = today - dt.timedelta(days=1)

    print("ğŸš€ ë‰´ìŠ¤ë ˆí„° ìƒì„± ì‹œì‘")

    # 1) ìˆ˜ì§‘ (ìµœëŒ€í•œ ë§ì´)
    all_articles = fetch_all_articles(cfg)
    _log("ì „ì²´ ìˆ˜ì§‘(ì›ë³¸)", len(all_articles))

    # 2) ì–´ì œ í•˜ë£¨ë§Œ
    y_articles = filter_yesterday_articles(all_articles, cfg)
    _log(f"ì–´ì œ({yesterday.isoformat()}) ê¸°ì‚¬ í•„í„° í›„", len(y_articles))

    # 3) íˆ¬ì/ì¬ë¬´ + ê°€ìˆ˜ ë‹¤ë¹„ì¹˜ ì œì™¸ (í•„í„°ëŠ” ìµœì†Œë§Œ)
    y_articles = filter_out_finance_articles(y_articles)
    _log("íˆ¬ì/ì¬ë¬´ + ê°€ìˆ˜ë‹¤ë¹„ì¹˜ ì œì™¸ í›„", len(y_articles))

    # 4) âœ… ì¤‘ë³µë§Œ ì‚­ì œ (ê³¼í•˜ê²Œ ì•ˆ ì§€ì›€)
    y_articles = dedup_articles_only_duplicates(y_articles)
    _log("ì¤‘ë³µ ì œê±° í›„", len(y_articles))

    # 5) ìš”ì•½ ë‹¤ë“¬ê¸°
    refine_article_summaries(y_articles)

    # 6) ë¶„ë¥˜
    categorized = categorize_articles(y_articles)

    # 7) ì „ì²´ ë¸Œë¦¬í•‘
    yesterday_summary = summarize_overall(y_articles)

    # 8) HTML
    html_body = render_newsletter_html(cfg, categorized, yesterday_summary)

    # 9) ë°œì†¡
    email_conf = cfg["email"]
    subject_prefix = email_conf.get("subject_prefix", "[Daily News]")
    subject = f"{subject_prefix} ì–´ì œ({yesterday.isoformat()}) ê¸°ì‚¬ ë¸Œë¦¬í•‘"

    send_email_html(
        subject=subject,
        html_body=html_body,
        from_addr=email_conf["from"],
        to_addrs=email_conf["to"],
    )

    print("âœ… ë°œì†¡ ì™„ë£Œ")


if __name__ == "__main__":
    main()
