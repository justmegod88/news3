import re
from typing import List, Optional
from urllib.parse import urlparse

# OpenAI ì‚¬ìš©ì€ ì„ íƒ(ì—†ì–´ë„ ë™ì‘)
try:
    from openai import OpenAI
except Exception:
    OpenAI = None

# ë³¸ë¬¸ í™•ì¸(ì¡°ê±´ë¶€)ìš©
import requests
from bs4 import BeautifulSoup


# =========================
# OpenAI client
# =========================
def _get_client():
    import os
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or OpenAI is None:
        return None
    return OpenAI(api_key=api_key)


# =========================
# Helpers
# =========================
def _norm_text(s: str) -> str:
    s = re.sub(r"\s+", " ", (s or "")).strip()
    s = re.sub(r"[\"'â€œâ€â€˜â€™]", "", s)
    return s


def _count_sentences(s: str) -> int:
    if not s:
        return 0
    parts = re.split(r"[.!?ã€‚ï¼ï¼Ÿ]", s)
    parts = [p.strip() for p in parts if p.strip()]
    return len(parts)


def _is_image_file_url(url: str) -> bool:
    try:
        path = urlparse(url or "").path.lower()
    except Exception:
        path = (url or "").lower()
    return path.endswith((".jpg", ".jpeg", ".png", ".gif", ".webp"))


def _is_meaningless_summary(summary: str) -> bool:
    s = _norm_text(summary).lower()
    if not s:
        return True

    meaningless_patterns = [
        "ìì„¸í•œ ë‚´ìš©", "ìì„¸íˆ ë³´ê¸°", "ìì„¸íˆë³´ê¸°",
        "ê¸°ì‚¬ ë³´ê¸°", "ê¸°ì‚¬ë³´ê¸°", "ì›ë¬¸ ë³´ê¸°", "ì›ë¬¸ë³´ê¸°",
        "ë”ë³´ê¸°", "ë³´ê¸°", "ë°”ë¡œê°€ê¸°",
        "ì‚¬ì§„", "ì´ë¯¸ì§€", "ì˜ìƒ", "ë™ì˜ìƒ",
        "ê´€ë ¨ ê¸°ì‚¬", "ê´€ë ¨ê¸°ì‚¬",
        "í´ë¦­", "í™•ì¸",
    ]

    if len(s) < 12:
        return True

    for p in meaningless_patterns:
        if p in s and len(s) <= 30:
            return True

    if re.fullmatch(r"(https?://\S+)", s):
        return True

    if len(re.sub(r"[a-z0-9ê°€-í£]", "", s)) / max(len(s), 1) > 0.65:
        return True

    return False


def _is_summary_same_as_title(title: str, summary: str) -> bool:
    t = _norm_text(title)
    s = _norm_text(summary)
    if not t or not s:
        return False

    if t == s:
        return True

    if t in s or s in t:
        if abs(len(t) - len(s)) <= 12:
            return True

    t2 = re.sub(r"[\[\(].*?[\]\)]", "", t).strip()
    s2 = re.sub(r"[\[\(].*?[\]\)]", "", s).strip()
    if t2 and s2 and t2 == s2:
        return True

    return False


def _fetch_html(url: str, timeout=(3.0, 6.0)) -> Optional[str]:
    if not url or not (url.startswith("http://") or url.startswith("https://")):
        return None

    headers = {
        "User-Agent": "Mozilla/5.0 (compatible; NewsBot/1.0)",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    }

    try:
        r = requests.get(url, headers=headers, timeout=timeout)
        r.raise_for_status()
        ct = (r.headers.get("Content-Type") or "").lower()
        if ct.startswith("image/"):
            return None
        return r.text or None
    except Exception:
        return None


def _extract_text_and_imgcount(html: str, max_chars: int = 3000) -> tuple[str, int]:
    soup = BeautifulSoup(html or "", "html.parser")

    for tag in soup(["script", "style", "noscript", "header", "footer", "nav", "aside"]):
        tag.decompose()

    img_count = len(soup.find_all("img"))

    text = soup.get_text("\n", strip=True)
    text = re.sub(r"[ \t]+", " ", text)
    text = re.sub(r"\n{2,}", "\n", text).strip()

    if max_chars and len(text) > max_chars:
        text = text[:max_chars].rstrip() + "â€¦"

    return text, img_count


def _is_image_only_ad_page(text: str, img_count: int) -> bool:
    t = _norm_text(text)
    if len(t) < 40 and img_count >= 1:
        return True
    if len(t) < 20:
        return True
    return False


# =========================
# OpenAI calls / prompts (â—ì›ë¬¸ ê·¸ëŒ€ë¡œ)
# =========================
def _call_openai_2to3_sentences(client, prompt: str, max_chars: int = 220) -> str:
    r = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
    )
    text = (r.choices[0].message.content or "").strip()
    text = re.sub(r"\s+", " ", text).strip()
    if len(text) > max_chars:
        text = text[:max_chars].rstrip() + "â€¦"
    return text


def _prompt_compress_long_summary(title: str, summary: str) -> str:
    return f"""
ë„ˆëŠ” ì—…ê³„ ë°ì¼ë¦¬ ë‰´ìŠ¤ë ˆí„° í¸ì§‘ìë‹¤.
ì•„ë˜ [ìš”ì•½ë¬¸]ì„ "2~3ë¬¸ì¥"ìœ¼ë¡œ ì••ì¶•í•˜ë¼.

ê·œì¹™(ë§¤ìš° ì¤‘ìš”):
- [ìš”ì•½ë¬¸]ì— ìˆëŠ” ì‚¬ì‹¤ë§Œ ìœ ì§€ (ìƒˆë¡œìš´ ì‚¬ì‹¤/ì¶”ì¸¡/í•´ì„ ê¸ˆì§€)
- ê³¼ì¥/í™ë³´ ë¬¸êµ¬ ê¸ˆì§€
- ê¸°ì‚¬ì— ì—†ëŠ” ë‹¨ì–´ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
- 2~3ë¬¸ì¥, 220ì ì´ë‚´

[ì œëª©]
{title}

[ìš”ì•½ë¬¸]
{summary}

[ì¶œë ¥]
""".strip()


def _prompt_title_only(title: str) -> str:
    return f"""
ë„ˆëŠ” ë‰´ìŠ¤ ìš”ì•½ì„ ë³´ì¡°í•˜ëŠ” í¸ì§‘ìë‹¤.
âš ï¸ ì´ ì‘ì—…ì€ ë§¤ìš° ì œí•œì ì¸ ì‘ì—…ì´ë‹¤.

ì•„ë˜ [ì œëª©]ì— í¬í•¨ëœ ì •ë³´ë§Œì„ ì‚¬ìš©í•´
ë¬¸ì¥ì„ 2~3ë¬¸ì¥ìœ¼ë¡œ "ì •ë¦¬"í•˜ë¼.

ğŸš« ì ˆëŒ€ ê·œì¹™ (ìœ„ë°˜ ê¸ˆì§€ / ì •ë§ ì¤‘ìš”):
- ì œëª©ì— ëª…ì‹œë˜ì§€ ì•Šì€ ì‚¬ì‹¤, ë°°ê²½, ì›ì¸, ê²°ê³¼ë¥¼ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ ê²ƒ
- ê¸°ì‚¬ ë³¸ë¬¸ì„ ì¶”ì¸¡í•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ë§¥ë½ì„ ë³´ì™„í•˜ì§€ ë§ ê²ƒ
- â€œ~ë¡œ ë³´ì¸ë‹¤â€, â€œ~í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤â€, â€œ~ì˜ë¯¸ê°€ ìˆë‹¤â€ ê°™ì€ í•´ì„ ê¸ˆì§€
- ì œëª©ì— ì—†ëŠ” ìˆ«ì/ì£¼ì²´/í–‰ìœ„/ì‹œì /ëª©ì ì„ ìƒˆë¡œ ë§Œë“¤ì§€ ë§ ê²ƒ
- ì œëª©ì— ì—†ëŠ” ë‹¨ì–´ë¥¼ ì˜ë¯¸ìƒ í™•ì¥í•˜ì—¬ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
- ê¸°ì‚¬ì— ì—†ëŠ” ë‹¨ì–´ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€

âœ… í—ˆìš©ë˜ëŠ” ì‘ì—…:
- ì œëª©ì— ìˆëŠ” ì •ë³´ë¥¼ ë¬¸ë²•ì ìœ¼ë¡œë§Œ ë‚˜ëˆ„ì–´ ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„
- í•˜ë‚˜ì˜ ê¸´ ì œëª©ì„ 2~3ê°œì˜ ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¦¬
- ë™ì¼ ì˜ë¯¸ ë‚´ì—ì„œ ì¡°ì‚¬/ì–´ìˆœ ì •ë„ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ì¡°ì •

ì¶œë ¥:
- ì‚¬ì‹¤ ì§„ìˆ í˜• ë¬¸ì¥ë§Œ
- 2~3ë¬¸ì¥
- 200ì ì´ë‚´
- ê³¼ì¥/í•´ì„/í‰ê°€ í‘œí˜„ ê¸ˆì§€

[ì œëª©]
{title}

[ì¶œë ¥]
""".strip()


def _prompt_summarize_from_body(title: str, body_text: str) -> str:
    return f"""
ë„ˆëŠ” ì—…ê³„ ë°ì¼ë¦¬ ë‰´ìŠ¤ë ˆí„° í¸ì§‘ìë‹¤.
ì•„ë˜ [ê¸°ì‚¬ ë³¸ë¬¸]ì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ê·¼ê±°ë¡œ 2~3ë¬¸ì¥ ìš”ì•½ì„ ì‘ì„±í•˜ë¼.

ê·œì¹™(ë§¤ìš° ì¤‘ìš”):
- ê³¼ì¥/ì¶”ì¸¡/í•´ì„ ê¸ˆì§€, ë³¸ë¬¸ì— ìˆëŠ” ì‚¬ì‹¤ë§Œ
- ê¸°ì‚¬ 'ì¶œì²˜(ì–¸ë¡ ì‚¬)'ë¥¼ ì œí’ˆ/ë¸Œëœë“œ/ì œì¡°ì‚¬ë¡œ í‘œí˜„í•˜ì§€ ë§ ê²ƒ
- ì•ˆê²½í…Œ/ë Œì¦ˆ/ì œí’ˆì˜ ë¸Œëœë“œëª…ì€ ë³¸ë¬¸ì— ëª…í™•íˆ ì–¸ê¸‰ëœ ê²½ìš°ì—ë§Œ ì‚¬ìš©
- ë¸Œëœë“œê°€ ë¶ˆëª…í™•í•˜ë©´ íŠ¹ì • ì£¼ì²´ë¥¼ ë‹¨ì •í•˜ì§€ ë§ ê²ƒ
- ê¸°ì‚¬ì— ì—†ëŠ” ë‹¨ì–´ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
- 2~3ë¬¸ì¥, 220ì ì´ë‚´
- ê°€ëŠ¥í•œ í•œ íŒ©íŠ¸(ë¬´ì—‡/ëˆ„ê°€/ë¬´ìŠ¨ ë‚´ìš©/ì–´ë–¤ ì¡°ì¹˜)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ

[ì œëª©]
{title}

[ê¸°ì‚¬ ë³¸ë¬¸]
{body_text}

[ì¶œë ¥]
""".strip()


# =========================
# âœ… A. ê¸°ì‚¬ë³„ summary ì •ì œ/ìƒì„± (ìµœì¢… í™•ì •)
# =========================
def refine_article_summaries(articles: List) -> None:
    """
    âœ… ìš”ì•½ ì •ì±…(í™•ì •ë³¸)

    1) summaryê°€ ê¸¸ë‹¤
       - 260ì ì´ìƒ OR ë¬¸ì¥ ìˆ˜ > 3
       â†’ ì••ì¶• í”„ë¡¬í”„íŠ¸

    2) summaryê°€ titleê³¼ ë™ì¼/ì‚¬ì‹¤ìƒ ë™ì¼
       â†’ title-only í”„ë¡¬í”„íŠ¸

    3) summaryê°€ ì—†ìŒ/ë¬´ì˜ë¯¸
       3-1) ì´ë¯¸ì§€ë§Œ ìˆëŠ” ê´‘ê³  â†’ ë¹ˆê°’
       3-2) ë³¸ë¬¸ í…ìŠ¤íŠ¸ â†’ body í”„ë¡¬í”„íŠ¸

    ê³µí†µ:
    - OpenAI ì—†ìœ¼ë©´ ì˜ë¯¸ ìƒì„± ì—†ì´ ë¬¸ì¥ 2~3ê°œë§Œ ìœ ì§€
    - ìµœì¢… summaryëŠ” 220ì ì´ë‚´
    """
    client = _get_client()

    LONG_SUMMARY_THRESHOLD = 260
    MAX_SUMMARY_CHARS = 220

    for a in articles:
        title = _norm_text(getattr(a, "title", "") or "")
        summary_raw = getattr(a, "summary", "") or ""
        summary = _norm_text(summary_raw)
        link = (getattr(a, "link", "") or "").strip()

        # ì´ë¯¸ì§€ ë§í¬ â†’ ê´‘ê³ 
        if _is_image_file_url(link):
            a.summary = ""
            continue

        # 3) summary ì—†ìŒ/ë¬´ì˜ë¯¸
        if not summary or _is_meaningless_summary(summary):
            html = _fetch_html(link)
            if not html:
                a.summary = ""
                continue

            body_text, img_count = _extract_text_and_imgcount(html)
            if _is_image_only_ad_page(body_text, img_count):
                a.summary = ""
                continue

            if client:
                prompt = _prompt_summarize_from_body(title, body_text)
                summary = _call_openai_2to3_sentences(client, prompt, MAX_SUMMARY_CHARS)
            else:
                sentences = re.split(r"(?<=[.!?ã€‚ï¼ï¼Ÿ])\s+", body_text)
                summary = " ".join(sentences[:3])

            a.summary = summary[:MAX_SUMMARY_CHARS]
            continue

        # 2) summary == title
        if _is_summary_same_as_title(title, summary):
            if client:
                prompt = _prompt_title_only(title)
                summary = _call_openai_2to3_sentences(client, prompt, 200)
            else:
                summary = title

            a.summary = summary[:MAX_SUMMARY_CHARS]
            continue

        # 1) summaryê°€ ê¸¸ë‹¤ (ğŸ”§ ë¬¸ì¥ ìˆ˜ ì¡°ê±´ í¬í•¨)
        if len(summary) >= LONG_SUMMARY_THRESHOLD or _count_sentences(summary) > 3:
            if client:
                prompt = _prompt_compress_long_summary(title, summary)
                summary = _call_openai_2to3_sentences(client, prompt, MAX_SUMMARY_CHARS)
            else:
                sentences = re.split(r"(?<=[.!?ã€‚ï¼ï¼Ÿ])\s+", summary)
                summary = " ".join(sentences[:3])

        if len(summary) > MAX_SUMMARY_CHARS:
            summary = summary[:MAX_SUMMARY_CHARS].rstrip() + "â€¦"

        a.summary = summary
